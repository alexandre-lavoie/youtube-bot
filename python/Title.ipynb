{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Title.ipynb\n",
    "## Generates Title from Fetched Data\n",
    "### LSTM Code by https://machinelearningmastery.com/text-generation-lstm-recurrent-neural-networks-python-keras/"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Imports"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "from tensorflow.keras.models import Model, Sequential\n",
    "from tensorflow.keras.layers import Dense, Dropout, CuDNNLSTM"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Global Variables"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "FILE_LOCATION = \"https://raw.githubusercontent.com/alexandre-lavoie/youtube-bot/master/data/database/CA_viewCount.csv\"\n",
    "MIN_TITLE_LENGTH = 11\n",
    "NUMBER_OF_TITLES = 10\n",
    "EPOCHS = 20\n",
    "BATCH_SIZE = 128"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Read and Cleanup Database"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "video_database = pd.read_csv(FILE_LOCATION)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "cleanup_database = video_database.replace('[^\\x00-\\x7F]+','',regex=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Get Character Dictionary"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "chars = [chr(i) for i in range(ord('!'), ord('Z')+1)]\n",
    "chars.extend(['|', ' ', '[', ']', '_'])\n",
    "char_to_int = dict((c, i) for i, c in enumerate(chars))\n",
    "int_to_char = dict((i, c) for i, c in enumerate(chars))\n",
    "n_vocabs = len(chars)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Converts Titles Into Training Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "title_int = []\n",
    "for title in cleanup_database[\"title\"]:\n",
    "    title_int.append ([char_to_int[letter] for letter in title.upper()])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "dataX = []\n",
    "dataY = []\n",
    "\n",
    "for title in title_int:\n",
    "    if(len(title) > MIN_TITLE_LENGTH):\n",
    "        for i in range(0, len(title)-MIN_TITLE_LENGTH):\n",
    "            dataX.append(title[i:(i+MIN_TITLE_LENGTH)])\n",
    "            dataY.append(title[i+MIN_TITLE_LENGTH])\n",
    "        \n",
    "n_patterns = len(dataX)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Vocab Length: 63\n",
      "Pattern Length: 11\n",
      "Number of patterns: 19449\n"
     ]
    }
   ],
   "source": [
    "print(\"Vocab Length: \" + str(n_vocabs))\n",
    "print(\"Pattern Length: \" + str(MIN_TITLE_LENGTH))\n",
    "print(\"Number of patterns: \" + str(n_patterns))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "X = np.reshape(dataX, (n_patterns, MIN_TITLE_LENGTH, 1))\n",
    "X = X/float(n_vocabs)\n",
    "y = np.eye(len(chars))[dataY]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# LSTM"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = Sequential()\n",
    "model.add(CuDNNLSTM(256, input_shape=(X.shape[1], X.shape[2]), return_sequences=True))\n",
    "model.add(Dropout(0.2))\n",
    "model.add(CuDNNLSTM(256))\n",
    "model.add(Dropout(0.2))\n",
    "model.add(Dense(y.shape[1], activation='softmax'))\n",
    "model.compile(loss='categorical_crossentropy', optimizer='adam')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/20\n",
      "19449/19449 [==============================] - 9s 478us/step - loss: 3.2653\n",
      "Epoch 2/20\n",
      "19449/19449 [==============================] - 3s 170us/step - loss: 3.2027\n",
      "Epoch 3/20\n",
      "19449/19449 [==============================] - 3s 170us/step - loss: 3.1962\n",
      "Epoch 4/20\n",
      "19449/19449 [==============================] - 3s 170us/step - loss: 3.1815\n",
      "Epoch 5/20\n",
      "19449/19449 [==============================] - 3s 171us/step - loss: 3.1348\n",
      "Epoch 6/20\n",
      "19449/19449 [==============================] - 3s 171us/step - loss: 3.0785\n",
      "Epoch 7/20\n",
      "19449/19449 [==============================] - 3s 171us/step - loss: 3.0212\n",
      "Epoch 8/20\n",
      "19449/19449 [==============================] - 3s 170us/step - loss: 2.9751\n",
      "Epoch 9/20\n",
      "19449/19449 [==============================] - 3s 171us/step - loss: 2.9343\n",
      "Epoch 10/20\n",
      "19449/19449 [==============================] - 3s 171us/step - loss: 2.8934\n",
      "Epoch 11/20\n",
      "19449/19449 [==============================] - 3s 170us/step - loss: 2.8557 0s - loss: 2\n",
      "Epoch 12/20\n",
      "19449/19449 [==============================] - 3s 170us/step - loss: 2.8195\n",
      "Epoch 13/20\n",
      "19449/19449 [==============================] - 3s 171us/step - loss: 2.7881\n",
      "Epoch 14/20\n",
      "19449/19449 [==============================] - 3s 171us/step - loss: 2.7553\n",
      "Epoch 15/20\n",
      "19449/19449 [==============================] - 3s 171us/step - loss: 2.7311\n",
      "Epoch 16/20\n",
      "19449/19449 [==============================] - 3s 171us/step - loss: 2.6943\n",
      "Epoch 17/20\n",
      "19449/19449 [==============================] - 3s 171us/step - loss: 2.6659\n",
      "Epoch 18/20\n",
      "19449/19449 [==============================] - 3s 171us/step - loss: 2.6309\n",
      "Epoch 19/20\n",
      "19449/19449 [==============================] - 3s 170us/step - loss: 2.6008\n",
      "Epoch 20/20\n",
      "19449/19449 [==============================] - 3s 170us/step - loss: 2.5618\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<tensorflow.python.keras.callbacks.History at 0x1b494ef0>"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.fit(X, y, epochs=EPOCHS, batch_size=BATCH_SIZE)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Predictions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "BELIEVE IT THE WOUREE VIDEO) FT. DAAT   OO THE  OO THE  OO THE  OO THE  OO THE  OO THE  OO THE  OO THE  OO THE \n",
      "TO WIN NINT TO BOO TOEE SIDEO) FT. DAAT   OO THE  OO THE  OO THE  OO THE  OO THE  OO THE  OO THE  OO THE  OO TH\n",
      "NCE STEWART TO BOO TOEE SIDEO) FT. DAAT   OO THE  OO THE  OO THE  OO THE  OO THE  OO THE  OO THE  OO THE  OO TH\n",
      "IG ENGLISH TOOE FO THE WOAEE TOU COO TOEE SIDEO) FT. DAAT   OO THE  OO THE  OO THE  OO THE  OO THE  OO THE  OO \n",
      "RIS CLUB SCE WOAEO   OO THE  OO THE  OO THE  OO THE  OO THE  OO THE  OO THE  OO THE  OO THE  OO THE  OO THE  OO\n",
      "ON SHARK AT THE WOAEE TOU COO TOEE SIDEO) FT. DAAT   OO THE  OO THE  OO THE  OO THE  OO THE  OO THE  OO THE  OO\n",
      "FICIAL TRAILER - TIE OO THE  OO THE  OO THE  OO THE  OO THE  OO THE  OO THE  OO THE  OO THE  OO THE  OO THE  OO\n",
      "REVENGE MAKE TOOES - TOE  OO THE  OO THE  OO THE  OO THE  OO THE  OO THE  OO THE  OO THE  OO THE  OO THE  OO TH\n",
      "(COLLEGE DENE TOACT OO COO THE WOUREE VIDEO) FT. DAAT   OO THE  OO THE  OO THE  OO THE  OO THE  OO THE  OO THE \n",
      "P 10 SATISF TOEEE - TIE OO THE  OO THE  OO THE  OO THE  OO THE  OO THE  OO THE  OO THE  OO THE  OO THE  OO THE \n"
     ]
    }
   ],
   "source": [
    "for _ in range(NUMBER_OF_TITLES):\n",
    "    start = np.random.randint(0, len(dataX)-1)\n",
    "    patt = dataX[start]\n",
    "    text = \"\"\n",
    "    for value in patt:\n",
    "        text += int_to_char[value] \n",
    "\n",
    "    for i in range(100):\n",
    "        xx = np.reshape(patt, (1, len(patt), 1))\n",
    "        xx = xx / float(n_vocabs)\n",
    "        prediction = model.predict(xx, verbose=0)\n",
    "        index = np.argmax(prediction)\n",
    "        text += int_to_char[index]\n",
    "        patt.append(index)\n",
    "        patt = patt[1:len(patt)]\n",
    "\n",
    "    print(text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.save(\"title.h5\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
