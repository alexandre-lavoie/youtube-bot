{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Title.ipynb\n",
    "## Generates Title from Fetched Data\n",
    "### LSTM Code by https://machinelearningmastery.com/text-generation-lstm-recurrent-neural-networks-python-keras/"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Imports"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "from tensorflow.keras.models import Model, Sequential\n",
    "from tensorflow.keras.layers import Dense, Dropout, CuDNNLSTM"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Global Variables"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "FILE_LOCATION = \"https://raw.githubusercontent.com/alexandre-lavoie/youtube-bot/master/data/database/CA_viewCount.csv\"\n",
    "MIN_TITLE_LENGTH = 11\n",
    "NUMBER_OF_TITLES = 10\n",
    "EPOCHS = 20\n",
    "BATCH_SIZE = 128"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Read and Cleanup Database"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "video_database = pd.read_csv(FILE_LOCATION)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "cleanup_database = video_database.replace('[^\\x00-\\x7F]+','',regex=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Get Character Dictionary"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "chars = [chr(i) for i in range(ord('!'), ord('Z')+1)]\n",
    "chars.extend(['|', ' ', '[', ']', '_'])\n",
    "char_to_int = dict((c, i) for i, c in enumerate(chars))\n",
    "int_to_char = dict((i, c) for i, c in enumerate(chars))\n",
    "n_vocabs = len(chars)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Converts Titles Into Training Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "title_int = []\n",
    "for title in cleanup_database[\"title\"]:\n",
    "    title_int.append ([char_to_int[letter] for letter in title.upper()])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "dataX = []\n",
    "dataY = []\n",
    "\n",
    "for title in title_int:\n",
    "    if(len(title) > MIN_TITLE_LENGTH):\n",
    "        for i in range(0, len(title)-MIN_TITLE_LENGTH):\n",
    "            dataX.append(title[i:(i+MIN_TITLE_LENGTH)])\n",
    "            dataY.append(title[i+MIN_TITLE_LENGTH])\n",
    "        \n",
    "n_patterns = len(dataX)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Vocab Length: 63\n",
      "Pattern Length: 11\n",
      "Number of patterns: 19449\n"
     ]
    }
   ],
   "source": [
    "print(\"Vocab Length: \" + str(n_vocabs))\n",
    "print(\"Pattern Length: \" + str(MIN_TITLE_LENGTH))\n",
    "print(\"Number of patterns: \" + str(n_patterns))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "X = np.reshape(dataX, (n_patterns, MIN_TITLE_LENGTH, 1))\n",
    "X = X/float(n_vocabs)\n",
    "y = np.eye(len(chars))[dataY]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# LSTM"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = Sequential()\n",
    "model.add(CuDNNLSTM(256, input_shape=(X.shape[1], X.shape[2]), return_sequences=True))\n",
    "model.add(Dropout(0.2))\n",
    "model.add(CuDNNLSTM(256))\n",
    "model.add(Dropout(0.2))\n",
    "model.add(Dense(y.shape[1], activation='softmax'))\n",
    "model.compile(loss='categorical_crossentropy', optimizer='adam')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/20\n",
      "19449/19449 [==============================] - 7s 359us/step - loss: 3.2582\n",
      "Epoch 2/20\n",
      "19449/19449 [==============================] - 3s 171us/step - loss: 3.2013\n",
      "Epoch 3/20\n",
      "19449/19449 [==============================] - 3s 171us/step - loss: 3.1946\n",
      "Epoch 4/20\n",
      "19449/19449 [==============================] - 3s 170us/step - loss: 3.1714\n",
      "Epoch 5/20\n",
      "19449/19449 [==============================] - 3s 171us/step - loss: 3.1236\n",
      "Epoch 6/20\n",
      "19449/19449 [==============================] - 3s 171us/step - loss: 3.0697\n",
      "Epoch 7/20\n",
      "19449/19449 [==============================] - 3s 170us/step - loss: 3.0116\n",
      "Epoch 8/20\n",
      "19449/19449 [==============================] - 3s 170us/step - loss: 2.9639\n",
      "Epoch 9/20\n",
      "19449/19449 [==============================] - 3s 170us/step - loss: 2.9224\n",
      "Epoch 10/20\n",
      "19449/19449 [==============================] - 3s 171us/step - loss: 2.8812\n",
      "Epoch 11/20\n",
      "19449/19449 [==============================] - 3s 171us/step - loss: 2.8463\n",
      "Epoch 12/20\n",
      "19449/19449 [==============================] - 3s 171us/step - loss: 2.8124\n",
      "Epoch 13/20\n",
      "19449/19449 [==============================] - 3s 171us/step - loss: 2.7786\n",
      "Epoch 14/20\n",
      "19449/19449 [==============================] - 3s 171us/step - loss: 2.7497\n",
      "Epoch 15/20\n",
      "19449/19449 [==============================] - 3s 171us/step - loss: 2.7156\n",
      "Epoch 16/20\n",
      "19449/19449 [==============================] - 3s 170us/step - loss: 2.6875\n",
      "Epoch 17/20\n",
      "19449/19449 [==============================] - 3s 171us/step - loss: 2.6548\n",
      "Epoch 18/20\n",
      "19449/19449 [==============================] - 3s 171us/step - loss: 2.6206\n",
      "Epoch 19/20\n",
      "19449/19449 [==============================] - 3s 171us/step - loss: 2.5954\n",
      "Epoch 20/20\n",
      "19449/19449 [==============================] - 3s 171us/step - loss: 2.5606\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<tensorflow.python.keras.callbacks.History at 0x1c435b70>"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.fit(X, y, epochs=EPOCHS, batch_size=BATCH_SIZE)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Predictions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "H ROME TITL FO THE SOOE  OO SEE WOOE  OO SEE WOOE  OO SEE WOOE  OO SEE WOOE  OO SEE WOOE  OO SEE WOOE  OO SEE W\n",
      "N HE SEES FO THE SOOE  OO SEE WOOE  OO SEE WOOE  OO SEE WOOE  OO SEE WOOE  OO SEE WOOE  OO SEE WOOE  OO SEE WOO\n",
      "S) | DEATH TOO SEE WOOL AOE TOEEE ( FANE TOACO   OU SEE WOOL AOE TOEEE ( FANE TOACO   OU SEE WOOL AOE TOEEE ( F\n",
      "UBLIC STATE TOEEE ( FANE TOACO   OU SEE WOOL AOE TOEEE ( FANE TOACO   OU SEE WOOL AOE TOEEE ( FANE TOACO   OU S\n",
      "OF THE YEAR AOO TOE SOOE  OU SEE WOOL AOE TOEEE ( FANE TOACO   OU SEE WOOL AOE TOEEE ( FANE TOACO   OU SEE WOOL\n",
      "&AMP;A ON KENE TO MECE ( FANE TOACO   OU SEE WOOL AOE TOEEE ( FANE TOACO   OU SEE WOOL AOE TOEEE ( FANE TOACO  \n",
      "FIGHTER ROGEC ( FENE MO SHE WOOE  OO SEE WOOE  OO SEE WOOE  OO SEE WOOE  OO SEE WOOE  OO SEE WOOE  OO SEE WOOE \n",
      "EAKDOWN +THINC AN THE SOOE  OO SEE WOOE  OO SEE WOOE  OO SEE WOOE  OO SEE WOOE  OO SEE WOOE  OO SEE WOOE  OO SE\n",
      "RY :DOUBLE TOEEE ( FANE TOACO   OU SEE WOOL AOE TOEEE ( FANE TOACO   OU SEE WOOL AOE TOEEE ( FANE TOACO   OU SE\n",
      "MMER FORGIN FO SHE SOOE  OO SEE WOOE  OO SEE WOOE  OO SEE WOOE  OO SEE WOOE  OO SEE WOOE  OO SEE WOOE  OO SEE W\n"
     ]
    }
   ],
   "source": [
    "for _ in range(NUMBER_OF_TITLES):\n",
    "    start = np.random.randint(0, len(dataX)-1)\n",
    "    patt = dataX[start]\n",
    "    text = \"\"\n",
    "    for value in patt:\n",
    "        text += int_to_char[value] \n",
    "\n",
    "    for i in range(100):\n",
    "        xx = np.reshape(patt, (1, len(patt), 1))\n",
    "        xx = xx / float(n_vocabs)\n",
    "        prediction = model.predict(xx, verbose=0)\n",
    "        index = np.argmax(prediction)\n",
    "        text += int_to_char[index]\n",
    "        patt.append(index)\n",
    "        patt = patt[1:len(patt)]\n",
    "\n",
    "    print(text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "model_json = model.to_json()\n",
    "with open(\"title_model.json\", \"w\") as json_file:\n",
    "    json_file.write(model_json)\n",
    "model.save_weights(\"title_model.h5\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
