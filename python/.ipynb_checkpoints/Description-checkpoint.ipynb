{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Description.ipynb\n",
    "## Generates Description from Fetched Data\n",
    "### LSTM Code by https://machinelearningmastery.com/text-generation-lstm-recurrent-neural-networks-python-keras/"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Imports"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "from tensorflow.keras.models import Model, Sequential\n",
    "from tensorflow.keras.layers import Dense, Dropout, CuDNNLSTM"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Global Variables"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "FILE_LOCATION = \"https://raw.githubusercontent.com/alexandre-lavoie/youtube-bot/master/data/database/CA_viewCount.csv\"\n",
    "MIN_TITLE_LENGTH = 31\n",
    "NUMBER_OF_DESCRIPTIONS = 10\n",
    "DESCRIPTION_LENGTH = 500\n",
    "EPOCHS = 20\n",
    "BATCH_SIZE = 128"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Read and Cleanup Database"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "video_database = pd.read_csv(FILE_LOCATION, error_bad_lines=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "cleanup_database = video_database.replace('[^\\x00-\\x7F]+','',regex=True)\n",
    "cleanup_database = cleanup_database.replace('(http|https)://([\\w_-]+(?:(?:\\.[\\w_-]+)+))([\\w.,@?^=%&:/~+#-]*[\\w@?^=%&/~+#-])?', 'URL', regex=True)\n",
    "cleanup_database = cleanup_database.replace(' \\.\\.\\.', '', regex=True)\n",
    "description_database = [description for description in cleanup_database[\"description\"] if isinstance(description,str)]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Get Character Dictionary"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "chars = [chr(i) for i in range(ord('!'), ord('Z')+1)]\n",
    "chars.extend(['|', ' ', '[', ']', '_', '~'])\n",
    "char_to_int = dict((c, i) for i, c in enumerate(chars))\n",
    "int_to_char = dict((i, c) for i, c in enumerate(chars))\n",
    "n_vocabs = len(chars)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Converts Titles Into Training Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "description_int = []\n",
    "for description in description_database:\n",
    "    description_int.append ([char_to_int[letter] for letter in description.upper()])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "dataX = []\n",
    "dataY = []\n",
    "\n",
    "for description in description_int:\n",
    "    for i in range(0, len(description)-MIN_TITLE_LENGTH):\n",
    "        dataX.append(description[i:(i+MIN_TITLE_LENGTH)])\n",
    "        dataY.append(description[i+MIN_TITLE_LENGTH])\n",
    "        \n",
    "n_patterns = len(dataX)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Vocab Length: 64\n",
      "Pattern Length: 31\n",
      "Number of patterns: 42061\n"
     ]
    }
   ],
   "source": [
    "print(\"Vocab Length: \" + str(n_vocabs))\n",
    "print(\"Pattern Length: \" + str(MIN_TITLE_LENGTH))\n",
    "print(\"Number of patterns: \" + str(n_patterns))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "X = np.reshape(dataX, (n_patterns, MIN_TITLE_LENGTH, 1))\n",
    "X = X/float(n_vocabs)\n",
    "y = np.eye(len(chars))[dataY]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# LSTM"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = Sequential()\n",
    "model.add(CuDNNLSTM(256, input_shape=(X.shape[1], X.shape[2]), return_sequences=True))\n",
    "model.add(Dropout(0.2))\n",
    "model.add(CuDNNLSTM(256))\n",
    "model.add(Dropout(0.2))\n",
    "model.add(Dense(y.shape[1], activation='softmax'))\n",
    "model.compile(loss='categorical_crossentropy', optimizer='adam')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/20\n",
      "42061/42061 [==============================] - 13s 312us/step - loss: 3.1347\n",
      "Epoch 2/20\n",
      "42061/42061 [==============================] - 10s 228us/step - loss: 3.0716\n",
      "Epoch 3/20\n",
      "42061/42061 [==============================] - 9s 225us/step - loss: 3.0221\n",
      "Epoch 4/20\n",
      "42061/42061 [==============================] - 9s 225us/step - loss: 2.9634\n",
      "Epoch 5/20\n",
      "42061/42061 [==============================] - 9s 225us/step - loss: 2.9005\n",
      "Epoch 6/20\n",
      "42061/42061 [==============================] - 9s 225us/step - loss: 2.8539\n",
      "Epoch 7/20\n",
      "42061/42061 [==============================] - 9s 225us/step - loss: 2.8130\n",
      "Epoch 8/20\n",
      "42061/42061 [==============================] - 9s 225us/step - loss: 2.7716\n",
      "Epoch 9/20\n",
      "42061/42061 [==============================] - 9s 225us/step - loss: 2.7364\n",
      "Epoch 10/20\n",
      "42061/42061 [==============================] - 9s 225us/step - loss: 2.6935\n",
      "Epoch 11/20\n",
      "42061/42061 [==============================] - 9s 225us/step - loss: 2.6515\n",
      "Epoch 12/20\n",
      "42061/42061 [==============================] - 9s 225us/step - loss: 2.6107\n",
      "Epoch 13/20\n",
      "42061/42061 [==============================] - 10s 227us/step - loss: 2.5649\n",
      "Epoch 14/20\n",
      "42061/42061 [==============================] - 10s 227us/step - loss: 2.5230\n",
      "Epoch 15/20\n",
      "42061/42061 [==============================] - 10s 228us/step - loss: 2.4843\n",
      "Epoch 16/20\n",
      "42061/42061 [==============================] - 10s 228us/step - loss: 2.4451\n",
      "Epoch 17/20\n",
      "42061/42061 [==============================] - 10s 229us/step - loss: 2.4002\n",
      "Epoch 18/20\n",
      "42061/42061 [==============================] - 10s 229us/step - loss: 2.3614\n",
      "Epoch 19/20\n",
      "42061/42061 [==============================] - 10s 229us/step - loss: 2.32211s - los - ETA: 0\n",
      "Epoch 20/20\n",
      "42061/42061 [==============================] - 10s 230us/step - loss: 2.2793\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<tensorflow.python.keras.callbacks.History at 0x1b468a58>"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.fit(X, y, epochs=EPOCHS, batch_size=BATCH_SIZE)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Predictions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "O BY THE CRANBERRIES PERFORMING THE SEAR THE SECO DOOMENT AND HAT AND MER ALD MER AND MN THE SECO THE SECO DOOMENT AND HAT AND MER ALD MER AND MN THE SECO THE SECO DOOMENT AND HAT AND MER ALD MER AND MN THE SECO THE SECO DOOMENT AND HAT AND MER ALD MER AND MN THE SECO THE SECO DOOMENT AND HAT AND MER ALD MER AND MN THE SECO THE SECO DOOMENT AND HAT AND MER ALD MER AND MN THE SECO THE SECO DOOMENT AND HAT AND MER ALD MER AND MN THE SECO THE SECO DOOMENT AND HAT AND MER ALD MER AND MN THE SECO THE SECO DOOMENT AND HAT AND MER A\n",
      " DREAM OF BECOMING A PHYSICIST AND SHE ARE IN THE WORLD THE SECO THE SECO DOOMENT AND HAT AND MER ALD MER AND MN THE SECO THE SECO DOOMENT AND HAT AND MER ALD MER AND MN THE SECO THE SECO DOOMENT AND HAT AND MER ALD MER AND MN THE SECO THE SECO DOOMENT AND HAT AND MER ALD MER AND MN THE SECO THE SECO DOOMENT AND HAT AND MER ALD MER AND MN THE SECO THE SECO DOOMENT AND HAT AND MER ALD MER AND MN THE SECO THE SECO DOOMENT AND HAT AND MER ALD MER AND MN THE SECO THE SECO DOOMENT AND HAT AND MER ALD MER AND MN THE SECO THE SECO D\n",
      "IVILEGE, THE AMENITIES, AND ALL THE WORL THE SECO THE SECO DOOMENT AND HAT AND MER ALD MER AND MN THE SECO THE SECO DOOMENT AND HAT AND MER ALD MER AND MN THE SECO THE SECO DOOMENT AND HAT AND MER ALD MER AND MN THE SECO THE SECO DOOMENT AND HAT AND MER ALD MER AND MN THE SECO THE SECO DOOMENT AND HAT AND MER ALD MER AND MN THE SECO THE SECO DOOMENT AND HAT AND MER ALD MER AND MN THE SECO THE SECO DOOMENT AND HAT AND MER ALD MER AND MN THE SECO THE SECO DOOMENT AND HAT AND MER ALD MER AND MN THE SECO THE SECO DOOMENT AND HAT \n",
      "EST-SELLING NOVEL ABOUT AN ANGEN OE THE SECO DOOMENT AND HAT AND MER ALD MER AND MN THE SECO THE SECO DOOMENT AND HAT AND MER ALD MER AND MN THE SECO THE SECO DOOMENT AND HAT AND MER ALD MER AND MN THE SECO THE SECO DOOMENT AND HAT AND MER ALD MER AND MN THE SECO THE SECO DOOMENT AND HAT AND MER ALD MER AND MN THE SECO THE SECO DOOMENT AND HAT AND MER ALD MER AND MN THE SECO THE SECO DOOMENT AND HAT AND MER ALD MER AND MN THE SECO THE SECO DOOMENT AND HAT AND MER ALD MER AND MN THE SECO THE SECO DOOMENT AND HAT AND MER ALD ME\n",
      " BACK TO LIFE AND IT LOOKS BRANE SO THE SECO THE SECO DOOMENT AND HAT AND MER ALD MER AND MN THE SECO THE SECO DOOMENT AND HAT AND MER ALD MER AND MN THE SECO THE SECO DOOMENT AND HAT AND MER ALD MER AND MN THE SECO THE SECO DOOMENT AND HAT AND MER ALD MER AND MN THE SECO THE SECO DOOMENT AND HAT AND MER ALD MER AND MN THE SECO THE SECO DOOMENT AND HAT AND MER ALD MER AND MN THE SECO THE SECO DOOMENT AND HAT AND MER ALD MER AND MN THE SECO THE SECO DOOMENT AND HAT AND MER ALD MER AND MN THE SECO THE SECO DOOMENT AND HAT AND M\n",
      "HE \"ANGRY BIRDS BLUES\" COMPILATION ON A POGATE OO THE SECO THE SECO DOOMENT AND HAT AND MER ALD MER AND MN THE SECO THE SECO DOOMENT AND HAT AND MER ALD MER AND MN THE SECO THE SECO DOOMENT AND HAT AND MER ALD MER AND MN THE SECO THE SECO DOOMENT AND HAT AND MER ALD MER AND MN THE SECO THE SECO DOOMENT AND HAT AND MER ALD MER AND MN THE SECO THE SECO DOOMENT AND HAT AND MER ALD MER AND MN THE SECO THE SECO DOOMENT AND HAT AND MER ALD MER AND MN THE SECO THE SECO DOOMENT AND HAT AND MER ALD MER AND MN THE SECO THE SECO DOOMENT\n",
      "F AND MEGAN FOX. AVAILABLE NOW ALDUM A AOA IN THE WORLD THE SECO THE SECO DOOMENT AND HAT AND MER ALD MER AND MN THE SECO THE SECO DOOMENT AND HAT AND MER ALD MER AND MN THE SECO THE SECO DOOMENT AND HAT AND MER ALD MER AND MN THE SECO THE SECO DOOMENT AND HAT AND MER ALD MER AND MN THE SECO THE SECO DOOMENT AND HAT AND MER ALD MER AND MN THE SECO THE SECO DOOMENT AND HAT AND MER ALD MER AND MN THE SECO THE SECO DOOMENT AND HAT AND MER ALD MER AND MN THE SECO THE SECO DOOMENT AND HAT AND MER ALD MER AND MN THE SECO THE SECO D\n",
      "NS PROJECT - OUT 12TH JULY: URL SHES DOE IN THE WORLD THE SECO DOENE THE SECO DOOMENT AND HAT AND MER ALD MER AND MN THE SECO THE SECO DOOMENT AND HAT AND MER ALD MER AND MN THE SECO THE SECO DOOMENT AND HAT AND MER ALD MER AND MN THE SECO THE SECO DOOMENT AND HAT AND MER ALD MER AND MN THE SECO THE SECO DOOMENT AND HAT AND MER ALD MER AND MN THE SECO THE SECO DOOMENT AND HAT AND MER ALD MER AND MN THE SECO THE SECO DOOMENT AND HAT AND MER ALD MER AND MN THE SECO THE SECO DOOMENT AND HAT AND MER ALD MER AND MN THE SECO THE SE\n",
      " HE'S GETTING OLD. IF YOU ENJOY AND MER ALD MER AND MN THE SECO THE SECO DOOMENT AND HAT AND MER ALD MER AND MN THE SECO THE SECO DOOMENT AND HAT AND MER ALD MER AND MN THE SECO THE SECO DOOMENT AND HAT AND MER ALD MER AND MN THE SECO THE SECO DOOMENT AND HAT AND MER ALD MER AND MN THE SECO THE SECO DOOMENT AND HAT AND MER ALD MER AND MN THE SECO THE SECO DOOMENT AND HAT AND MER ALD MER AND MN THE SECO THE SECO DOOMENT AND HAT AND MER ALD MER AND MN THE SECO THE SECO DOOMENT AND HAT AND MER ALD MER AND MN THE SECO THE SECO DO\n",
      "WONDERS LIKE THE GRAND CANYON AND HOR THE WETEH TO THE SEAR THE SECO THE SECO DOOMENT AND HAT AND MER ALD MER AND MN THE SECO THE SECO DOOMENT AND HAT AND MER ALD MER AND MN THE SECO THE SECO DOOMENT AND HAT AND MER ALD MER AND MN THE SECO THE SECO DOOMENT AND HAT AND MER ALD MER AND MN THE SECO THE SECO DOOMENT AND HAT AND MER ALD MER AND MN THE SECO THE SECO DOOMENT AND HAT AND MER ALD MER AND MN THE SECO THE SECO DOOMENT AND HAT AND MER ALD MER AND MN THE SECO THE SECO DOOMENT AND HAT AND MER ALD MER AND MN THE SECO THE SE\n"
     ]
    }
   ],
   "source": [
    "for _ in range(NUMBER_OF_DESCRIPTIONS):\n",
    "    start = np.random.randint(0, len(dataX)-1)\n",
    "    patt = dataX[start]\n",
    "    text = \"\"\n",
    "    for value in patt:\n",
    "        text += int_to_char[value]\n",
    "\n",
    "    for i in range(DESCRIPTION_LENGTH):\n",
    "        xx = np.reshape(patt, (1, len(patt), 1))\n",
    "        xx = xx / float(n_vocabs)\n",
    "        prediction = model.predict(xx, verbose=0)\n",
    "        index = np.argmax(prediction)\n",
    "        text += int_to_char[index]\n",
    "        patt.append(index)\n",
    "        patt = patt[1:len(patt)]\n",
    "\n",
    "    print(text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "model_json = model.to_json()\n",
    "with open(\"description_model.json\", \"w\") as json_file:\n",
    "    json_file.write(model_json)\n",
    "model.save_weights(\"description_model.h5\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
